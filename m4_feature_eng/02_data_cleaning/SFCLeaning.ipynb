{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing values\n",
    "-What is the missing datatype used in pandas?\n",
    "\n",
    "It's Nans\n",
    "\n",
    "-How to replace all occurences of the value 9999 to missing in pandas?\n",
    "\n",
    "\n",
    "turn them into Nans\n",
    "for col in df1:\n",
    "    for i, val in enumerate(col):\n",
    "        if df[col][i] == -9999:\n",
    "            df[col][i] = numpy.NaN\n",
    "\n",
    "-How to get the absolute number of missings for each variable in pandas?\n",
    "\n",
    "np.isnan(df.values).sum()\n",
    "\n",
    "-How to get the percentage of missings for each variable in pandas?\n",
    "\n",
    "percent_missing = df.isnull().sum() * 100 / len(df) missing_value_df = pd\n",
    "\n",
    "-How to drop rows with missing values?\n",
    "\n",
    "df.dropna() #drops row if at least 1 value is Nan\n",
    "df.dropna(how = 'all') # if all are Nan\n",
    "\n",
    "-How to drop variables with missing values?\n",
    "\n",
    "# dropping column with all null values \n",
    "new.dropna(axis = 1, inplace = True) \n",
    "\n",
    "-What is the univariate imputation method in sklearn?\n",
    "\n",
    "One type of imputation algorithm is univariate, which imputes values in the i-th feature dimension using only non-missing values in that feature dimension (e.g. impute.SimpleImputer).\n",
    "\n",
    "-What is the multivariate imputation method in sklearn?\n",
    "\n",
    "By contrast, multivariate imputation algorithms use the entire set of available feature dimensions to estimate the missing values (e.g. impute.IterativeImputer)\n",
    "\n",
    "-What is the best univariate imputation method to categorical variables? (Explain why)\n",
    "\n",
    "I don't know yet\n",
    "Maybe Simple Impute?\n",
    "\n",
    "#Impute the values using scikit-learn SimpleImpute Class\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "imp_mean = SimpleImputer( strategy='most_frequent')\n",
    "imp_mean.fit(train)\n",
    "imputed_train_df = imp_mean.transform(train)\n",
    "\n",
    "https://towardsdatascience.com/6-different-ways-to-compensate-for-missing-values-data-imputation-with-examples-6022d9ca0779\n",
    "\n",
    "-What is the best univariate imputation method to numerical variables? (Explain why)\n",
    "\n",
    "constant imputation?\n",
    "\n",
    "-What is an outlier?\n",
    "\n",
    "An outlier is an observation that lies an abnormal distance from other values in a random sample from a population. In a sense, this definition leaves it up to the analyst (or a consensus process) to decide what will be considered abnormal.\n",
    "\n",
    "-What is a simple method to detect and deal with outliers of a numerical variable?\n",
    "\n",
    "Visualizing\n",
    "\n",
    "-What is novelty detection?\n",
    "\n",
    "Novelty detection is a statistical method used to determine new or unknown data and determining if these new data are within the norm (inlier) or outside of it (outlier).\n",
    "\n",
    "-Name 4 advanced methods of outlier detection in sklearn.\n",
    "\n",
    "Isolation Forest\n",
    "Minimum Covariance Determinant\n",
    "Local Outlier Factor\n",
    "One-Class SVM\n",
    "\n",
    "-What is a typo?\n",
    "\n",
    "An error in spelling or writing\n",
    "\n",
    "-What is a good method of automatically detect typos?\n",
    "\n",
    "FuzzyWuzzy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas   1.1.3\n",
      "Sklearn  0.23.2\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-0f03a75bfff8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m  \u001b[1;32mimport\u001b[0m \u001b[0menable_hist_gradient_boosting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensemble\u001b[0m      \u001b[1;32mimport\u001b[0m \u001b[0mHistGradientBoostingClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m               \u001b[1;32mimport\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplot_tree\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mlightgbm\u001b[0m              \u001b[1;32mimport\u001b[0m \u001b[0mLGBMClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcatboost\u001b[0m              \u001b[1;32mimport\u001b[0m \u001b[0mCatBoostClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "import numpy    as np\n",
    "import pandas   as pd\n",
    "import seaborn  as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn  as skl\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "sb.set_style(\"whitegrid\")\n",
    "skl.set_config(display='diagram')\n",
    "\n",
    "from sklearn import pipeline      # Pipeline, make_pipeline\n",
    "from sklearn import preprocessing # StandardScaler, OrdinalEncoder, LabelEncoder\n",
    "from sklearn import impute\n",
    "from sklearn import compose\n",
    "from sklearn import model_selection # train_test_split, StratifiedKFold, cross_val_score, cross_val_predict\n",
    "from sklearn import metrics         # accuracy_score, balanced_accuracy_score, plot_confusion_matrix\n",
    "from sklearn import inspection      # permutation_importance\n",
    "import scikitplot as skplt\n",
    "\n",
    "print(\"Pandas  \", pd.__version__)\n",
    "print(\"Sklearn \", skl.__version__)\n",
    "\n",
    "from sklearn.linear_model   import LogisticRegression\n",
    "from sklearn.linear_model   import RidgeClassifier\n",
    "from sklearn.svm            import SVC\n",
    "from sklearn.svm            import NuSVC\n",
    "from sklearn.svm            import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors      import KNeighborsClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.naive_bayes    import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble       import StackingClassifier\n",
    "\n",
    "#### TREE\n",
    "from sklearn.tree          import DecisionTreeClassifier\n",
    "from sklearn.ensemble      import RandomForestClassifier\n",
    "from sklearn.ensemble      import ExtraTreesClassifier\n",
    "from sklearn.ensemble      import AdaBoostClassifier\n",
    "from sklearn.ensemble      import GradientBoostingClassifier\n",
    "from sklearn.experimental  import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble      import HistGradientBoostingClassifier\n",
    "from xgboost               import XGBClassifier, plot_tree\n",
    "from lightgbm              import LGBMClassifier\n",
    "from catboost              import CatBoostClassifier\n",
    "#from ngboost               import NGBClassifier\n",
    "#from rgf.sklearn           import RGFClassifier, FastRGFClassifier\n",
    "\n",
    "########################################################### REGRESSORS\n",
    "from sklearn.linear_model  import ElasticNet, Ridge, Lasso, BayesianRidge, ARDRegression, TweedieRegressor\n",
    "from sklearn.svm           import LinearSVR, NuSVR, SVR\n",
    "from sklearn.ensemble      import BaggingRegressor\n",
    "from sklearn.kernel_ridge  import KernelRidge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196684"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "df = pd.read_csv('Building_Permits.csv')\n",
    "\n",
    "\n",
    "df['Street Number Suffix'].isnull().sum().sum()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
